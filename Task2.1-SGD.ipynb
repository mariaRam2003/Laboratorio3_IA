{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 722481.2579785364\n",
      "Epoch: 1000, Loss: 955205.0501226211\n",
      "Epoch: 2000, Loss: 380111.81842931104\n",
      "Epoch: 3000, Loss: 344413.40593131847\n",
      "Epoch: 4000, Loss: 1081063.7078354768\n",
      "Epoch: 5000, Loss: 626328.7253876392\n",
      "Epoch: 6000, Loss: 765239.6054674268\n",
      "Epoch: 7000, Loss: 1046183.3276161947\n",
      "Epoch: 8000, Loss: 317796.711149956\n",
      "Epoch: 9000, Loss: 737059.7592721945\n",
      "Epoch: 10000, Loss: 372965.21035216446\n",
      "Epoch: 11000, Loss: 1024931.4629286996\n",
      "Epoch: 12000, Loss: 179224.2710946086\n",
      "Epoch: 13000, Loss: 720223.8035329032\n",
      "Epoch: 14000, Loss: 768653.870121735\n",
      "Epoch: 15000, Loss: 954524.7883935403\n",
      "Epoch: 16000, Loss: 867093.7529273047\n",
      "Epoch: 17000, Loss: 912653.9259843328\n",
      "Epoch: 18000, Loss: 223043.28798599268\n",
      "Epoch: 19000, Loss: 140963.0999952054\n",
      "Epoch: 20000, Loss: 252003.7589391498\n",
      "Epoch: 21000, Loss: 708307.4663618379\n",
      "Epoch: 22000, Loss: 274439.3713501629\n",
      "Epoch: 23000, Loss: 1163514.3198975557\n",
      "Epoch: 24000, Loss: 834320.0130365567\n",
      "Epoch: 25000, Loss: 513616.24527539546\n",
      "Epoch: 26000, Loss: 742482.3568756608\n",
      "Epoch: 27000, Loss: 203023.9109854659\n",
      "Epoch: 28000, Loss: 596788.4805393858\n",
      "Epoch: 29000, Loss: 552337.6493265689\n",
      "Epoch: 30000, Loss: 738215.526884045\n",
      "Epoch: 31000, Loss: 655695.4064286648\n",
      "Epoch: 32000, Loss: 178673.8321698539\n",
      "Epoch: 33000, Loss: 583735.9038693199\n",
      "Epoch: 34000, Loss: 654770.5726372697\n",
      "Epoch: 35000, Loss: 669998.1009629662\n",
      "Epoch: 36000, Loss: 1204905.445305369\n",
      "Epoch: 37000, Loss: 727284.0826862832\n",
      "Epoch: 38000, Loss: 365395.1659702698\n",
      "Epoch: 39000, Loss: 1083782.4277301\n",
      "Epoch: 40000, Loss: 959994.3313985514\n",
      "Epoch: 41000, Loss: 519610.99909918476\n",
      "Epoch: 42000, Loss: 782978.8210246142\n",
      "Epoch: 43000, Loss: 604611.9391659651\n",
      "Epoch: 44000, Loss: 279843.10994223895\n",
      "Epoch: 45000, Loss: 1048548.9996389743\n",
      "Epoch: 46000, Loss: 333960.91987628036\n",
      "Epoch: 47000, Loss: 550475.1310031947\n",
      "Epoch: 48000, Loss: 548385.4472225978\n",
      "Epoch: 49000, Loss: 568210.1051069121\n",
      "Epoch: 50000, Loss: 517611.67778216046\n",
      "Epoch: 51000, Loss: 430599.90771101054\n",
      "Epoch: 52000, Loss: 883484.5241623458\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [43], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     32\u001b[0m     mini_batch \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(BATCH_RANGE[\u001b[38;5;241m0\u001b[39m], BATCH_RANGE[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), BATCH_SIZE)\n\u001b[0;32m---> 34\u001b[0m     m \u001b[38;5;241m=\u001b[39m m \u001b[38;5;241m-\u001b[39m LEARNING_RATE \u001b[38;5;241m*\u001b[39m \u001b[43mm_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     c \u001b[38;5;241m=\u001b[39m c \u001b[38;5;241m-\u001b[39m LEARNING_RATE \u001b[38;5;241m*\u001b[39m c_derivative(mini_batch)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _ \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn [43], line 16\u001b[0m, in \u001b[0;36mm_derivative\u001b[0;34m(x_mini_batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mm_derivative\u001b[39m(x_mini_batch : np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     15\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x_mini_batch)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mn)\u001b[38;5;241m*\u001b[39m(x_mini_batch \u001b[38;5;241m*\u001b[39m (\u001b[43my_actual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_mini_batch\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m y_predicted(x_mini_batch)))\u001b[38;5;241m.\u001b[39msum()\n",
      "Cell \u001b[0;32mIn [43], line 24\u001b[0m, in \u001b[0;36my_actual\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21my_actual\u001b[39m(x : np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m---> 24\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOLY_COEFICIENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mpolyval\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/numpy/lib/polynomial.py:771\u001b[0m, in \u001b[0;36mpolyval\u001b[0;34m(p, x)\u001b[0m\n\u001b[1;32m    769\u001b[0m     y \u001b[38;5;241m=\u001b[39m NX\u001b[38;5;241m.\u001b[39mzeros_like(x)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(p)):\n\u001b[0;32m--> 771\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100000\n",
    "LEARNING_RATE = 0.00000001\n",
    "BATCH_SIZE = 10\n",
    "BATCH_RANGE = (3, 10)\n",
    "POLY_COEFICIENTS = [2,-3,5,3]\n",
    "\n",
    "m = 1\n",
    "c = 0\n",
    "\n",
    "def loss_function(x_mini_batch : np.ndarray):\n",
    "    n = len(x_mini_batch)\n",
    "    return (1/n)*((y_actual(x_mini_batch) - y_predicted(x_mini_batch))**2).sum()\n",
    "    \n",
    "def m_derivative(x_mini_batch : np.ndarray):\n",
    "    n = len(x_mini_batch)\n",
    "    return(-2/n)*(x_mini_batch * (y_actual(x_mini_batch) - y_predicted(x_mini_batch))).sum()\n",
    "\n",
    "def c_derivative(x_mini_batch : np.ndarray):\n",
    "    n = len(x_mini_batch)\n",
    "    return (-2/n)*(y_actual(x_mini_batch) - y_predicted(x_mini_batch)).sum()\n",
    "    \n",
    "\n",
    "def y_actual(x : np.ndarray):\n",
    "    res = np.polyval(POLY_COEFICIENTS, x)\n",
    "    return res\n",
    "\n",
    "def y_predicted(x : np.ndarray):\n",
    "    global m, c\n",
    "    return m * x + c\n",
    "\n",
    "for _ in range(EPOCHS):\n",
    "    mini_batch = np.random.choice(np.arange(BATCH_RANGE[0], BATCH_RANGE[1] + 1), BATCH_SIZE)\n",
    "\n",
    "    m = m - LEARNING_RATE * m_derivative(mini_batch)\n",
    "    c = c - LEARNING_RATE * c_derivative(mini_batch)\n",
    "\n",
    "    if _ % 1000 == 0:\n",
    "        print(f\"Epoch: {_}, Loss: {loss_function(mini_batch)}\")\n",
    "\n",
    "print(f\"m: {m}, c: {c}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 3\n",
    "\n",
    "------------\n",
    "\n",
    "María Marta Ramirez Gil  21342                                   \n",
    "Gustavo Andrés Gonzalez Pineda 21438  \n",
    "\n",
    "Inteligencia Artificial                                                   \n",
    "Universidad del Valle de Guatemala\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explique la diferencia entre descenso de gradiente, descenso de gradiente por mini batches y descenso de\n",
    "gradiente estocástico. Asegúrese de mencionar las ventajas y desventajas de cada enfoque.\n",
    "\n",
    "- Descenso de gradiente: es un método que calcula el gradiente de la función de perdida respecto a todos los datos de entrenamiento en cada iteración y actualiza los parámetros en la dirección opuesta al gradiente para minimizar la perdida. Su ventaja es que converge hacia el mínimo global si la función de pérdida es convexa. Y su desventaja es que es computacionalmente costoso cuando se usan grandes conjuntos de datos.\n",
    "- Descenso de gradiente por mini batches: en este método los datos de entrenamiento se dividen en lotes más pequeños (mini batches) y el gradiente se calcula y los parámetros se actualizan para cada lote. Su ventaja es que reduce la carga computacional al trabajar con lotes pequeños. Pero su desventaja es que puede ser menos preciso que el descenso de gradiente completo, debido a la variabilidad de lotes.\n",
    "- Desceso de gradiente estocástico: en este enfoque, se selecciona aleatoriamente un solo ejemplo de entrenamiento en cada iteración para calcular el gradiente y actualizar los parámetros. Su ventaja es que converge más rapido en muchos casos, esto debido a las actualizaciones más frecuentes. Y su desventaja es que puede ser más \"ruidoso\" y menos estable debido a la aleatoriedad en la selección de ejemplos.\n",
    "\n",
    "Ferreira, E. V. Gradiente descendente.\n",
    "Blanco, P. A. (2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compare y contraste técnicas de extracción de features (feature extraction) y selección de features\n",
    "(feature selection) en machine learning. De ejemplos de escenarios donde cada técnica sería más apropiada.\n",
    "\n",
    "- Extracción de features: esta consiste en construir nuevas características o representaciones de los datos originales. Un ejemplo puede ser el uso de técnicas como PCA (Análisis de Componentes Principales) o autoencoders para obtener representaciones mas compactas y significativas de los datos. Es apropiado cuando los datos tienen muchas características redundantes o cuando se necesita reducir la dimnesionalidad de los datos.\n",
    "- Selección de features: esta implica seleccionar un subconjunto de caracterísitcas del conjunto original. Esto puede ser basado en técnicas estadísticas como la correlación de algoritmos de aprendizaje automático como árboles de decisión. Es apto cuando se requiere mejorar la eficiencia computacional, reducir el riesgo de sobreajuste o aumentar la interpretabilidad del modelo.\n",
    "\n",
    "Zebari, R., et al (2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Describa la arquitectura y el funcionamiento de un perceptrón de una sola capa (un tipo de red neuronal sin backpropagation). Explique cómo aprende y la forma en la que actualiza sus parámetros.\n",
    "\n",
    "Un perceptrón de una sola capa consta de una capa de entrada de nodos, una capa de salida de nodos y conexiones ponderadas entre estos. Cada conexión está asociada con un peso que se multiplica por la entrada y luego se suma para calcular la salidda. Esta salida se pasa a través de una función de activación, tipicamente una funcion escalon o una función sigmoide.\n",
    "\n",
    "El perceptrón aprende ajustanto los pesos de las conexiones para minimizar la función de pérdida. En cada iteración, se presenta un ejemplo de entrenamiento y se calcula la salida del perceptrón. Si esta salida es incorrecta, los pesos se ajustan de acuerdo con una regla de aprendizaje como el algoritmo de perceptrón, que aumenta o disminuye los pesos en función de la discrepancia entre la salida deseada y la salida real, multiplicada por la entrada correspondiente. Este proceso se repite para todos los ejemplo de entrenamiento hasta que se alcanza un criterio de convergencia.\n",
    "\n",
    "Gallant, S. I. (1990)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "- Blanco, P. A. (2016). Algoritmo de retropropagación. Recuperado de http://www. cs. us. es/~ fsancho/ficheros/IAML/2016/Sesion04/semi nario_BP. pdf.\n",
    "\n",
    "- Zebari, R., Abdulazeez, A., Zeebaree, D., Zebari, D., & Saeed, J. (2020). A comprehensive review of dimensionality reduction techniques for feature selection and feature extraction. Journal of Applied Science and Technology Trends, 1(2), 56-70.\n",
    "\n",
    "- Gallant, S. I. (1990). Perceptron-based learning algorithms. IEEE Transactions on neural networks, 1(2), 179-191."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
